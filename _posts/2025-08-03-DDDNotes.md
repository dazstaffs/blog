---
layout: post
title: "AZ-900 Microsoft Azure Fundamentals - Key Takeaways"
date: 2025-08-03
categories: [ddd]
---

DDD Reading or Developer Developer Developer Reading, for many years was my favourite event of the year. Hundreds of Software Engineers would flock to the Microsoft HQ at Reading (on a Saturday as well!) to listen to the best speakers talk on software engineering subjects. It was impossible for a software engineer to not walk away from the event without a renewed sense of curiousity and for me, it was also a time to catch-up with my friends from my days at Stericycle Expert Solutions. Sadly DDD Reading did not survive the COVID shutdown, but other DDD events still live-on across the country each year but hopefully the notes I made can inspire you to attend an event for yourself.

In this article, I'm not going to attempt to summarise years of DDD notes, because, for example, notes from 2017 are no longer relevant in this fast paced tech world, but I will summarise the sessions I think are still relevant.

---

**DDD Reading 2017-- Goodbye REST: Hello GraphQL**

- GraphQL, the QL stands for Query Language.
- Allows you to query a web service to get only the data you need by building a graph which essentially is just an object.
- Introspection allows you to inspect which fields you can pull back from the web service.

Sandeep's NHS tool used the following:

- SQLite
- Express
- Node
- Angular
- GraphQL

You can learn GraphQL at [http://graphql.org/learn](http://graphql.org/learn)

**DDD Reading 2017 - 10 More Things you need to do to succeed as a Tech Lead**

The original 10 points were this:

1. Having Coding Standards
2. Process & Automation
3. Use Personas.
4. Use sketches
5. Nuget all the things.
6. Handle Technical Debt
7. Use MDDs(Mini Design Documents) and POLs
8. Drive Sprint Planning
9. Listen, Appraise, Decide
10. Learn & Share

The 10 more things:

1. Breaks Things Up -- Break everything into bitesize pieces. BA's think of features not PBIs(Product Backlog Items) and Epics.
2. Instrumentation:
   a. Capture data
   b. Think about what to capture?
   c. This shouldn't be an afterthought, you should start measuring immediately from project start.
   d. Counters, gauges & meters.
   e. Histograms,
   f. Timers,
   g. Latency,
   h. SPLUNK will help you visualise this data.
   i. Metrics.net is another good example that comes with a dashboard.
   j. Server OS counters can help as well.
3. Benchmark Performance:
   a. Capture loads times with chrome dev tools
   b. Browser performance is important
   c. Measure from project start
   d. Test loads times from countries like America
   e. Measure runtime
   f. Test against representative data, 1000 records may perform amazing well but what about 2.8 million?
   g. If testing is still successful with 2.8 million records then you've probably chosen the right technologies.
4. Track Your Technical Debt:
   a. Can be in a spreadsheet
   b. SonarLint/SolarQube:
   i. Code quality dashboard
   ii. Analyses source code
   iii. Records results
   iv. Track changes
5. Production Readiness -- Ask yourself these key questions, Is it:
   a. Tested?
   b. Usable?
   c. Reviewed?
   d. Logging?
   e. Monitors?
   f. Instrumented?
   g. Manageable?
   h. Versioned?
   i. Deployable?
   j. Discoverable?
   k. Dashboards?
   l. Benchmarked?
6. Step away from the Shiny new technologies:
   a. Is this new technology fit for purpose?
   b. Is it efficient?
   c. New tools = new problems.
   d. Prototype & evaluate new technologies first.
   e. .NET core is loved by many developers but has its flaws.
7. Security
   a. Knowledge out there is poor so you must educate your teams.
   b. Google top 10 breaches of security and you'll see that over the top 10 breaches over 37 millions records have been leaked.
   c. Breaches can be a PR disaster; 24x7 media can bring a company to its knees.
   d. Build a security culture.
   e. Where is your data stored exactly; what are your attack vectors?
   f. Are you complying with Compliance Regulations?
   g. Never write your own security code. Cryptography and Authentication algorithms should be left to the mathematicians, Azure AD and 2FF experts.
   h. 1 Penetration test before deployment is never enough.
8. Clean Code Sessions
   a. A meeting with developers to discuss problems and approaches with no Project Management influence will deliver great results.
   b. Unconference style with no agenda.
   c. Not just a moan session.
   d. Put issues on a whiteboard.
   e. Mini DDD session
   f. Tech Lead should bring issues in-case no one has any to start the session off.
   g. Everyone contributes
   h. Invite guests.
   i. Show'n'Tell in every session.
9. It's all about money
   a. Cost per feature
   b. Hardware & Software costs.
   c. Developers costs
   d. Prototype costs
   e. Azure costs
10. KISSALAP
    a. Keep It Simple As Long As Possible
    b. Balance YAGNI vs Product Capability
    c. Delaying Complexity vs Technical Debt
    d. Rework a prototype vs build from scratch.

**DDD Reading 2018 - How Microsoft Does Dev Ops**

- TFS
- VSTS
- 3500 developers at MS
- Release a BETA version, take customer feedback, improves the software and release is the MS ethos.
- "Culture eats strategy for breakfast"
- Stable, self-managing, cross purpose teams is key.
- Team stability is very important. No team changes for 12 months was the goal.
- MS did a stickynote exercise to create self-forming teams.
  - Managers were scared of losing all their staff to other teams so Managers started to market themselves to MS employees.
  - Each person had 3 postitis for 1st, 2nd and 3rd team choices. On a whiteboard the postits were placed under different teams.
  - Only 20% of people actually wanted to change teams.
  - Only 1 person was forced to a team. 90% got their first choice.
  - Cross pollinating talent was also a goal.
- Daniel H Pink's book -- DriVE was key in the decision to change all the teams.
- "Autonomy, Mastery and Purpose"
- Intrinsic motivators vs extrinsic motivators.
- Alignment vs Autonomy balance.
- Teams work in Scrum, KANBAN or however they want as long as they deliver value.
- Fixed 3 week sprints. All sprints across the teams are aligned though so all teams end their 3 weeks on the same day.
- Bug cap of 5 per Engineer. If your team has 10 engineers x 5 bugs that means a max of 50 bugs before dev work must stop to fix the bugs and therefore less features in the next sprint.
- No admin wasted on timesheets unless the team really wants them.
- There was an alignment project to ensure all teams used MSTS, git, etc.
- How to sync your teams?
  - Sprint Mail
    - What was achieved this sprint?
    - Video Demo (Max 5 mins) because competitive teams meant all kinds of fancy video editing which meant long videos.
    - What value was delivered?
    - What's in the next sprint?
  - Quarterly leadership meetings
    - Next 3 sprints?
    - Is the team healthy?
    - Risks or issues to highlight?
  - Experience Reviews
    - Are storyboards consistent with code?
    - High level execution plans. Not MS Project -- even MS don't use it.
    - "Plans are worthless, but planning is everything"
  - Planning Strategy Document
    - 6 pages max
    - This sprint = Team Responsibility
    - Next 3 sprints = Team Responsibility
    - Next Season (6 months) = Team + Leadership Responsibility
    - Next Year (12 months) = Leadership Responsibility
- Team plans change especially when GDPR came along.
- Moved into the cloud in 2011.
- Use git for a repo
  - Everyone works from Master Branch.
  - Engineers don't merge what they didn't write.
  - You broke it, you fix it!
  - Pull requests are validated to ensure they'll run.
  - Checks run to ensure no passwords were changed that will break master.
  - All tests must pass before a new version is deployed to master to ensure previously written functionality been broken.
  - Tests are trusted.
- Quality ownership role works on a rotation. All roles in the team work on a rotation.
- Team roles:
  - Program Management
  - Devs (UI, Frontend, Backend, etc)
- All developers had to write tests, some didn't want to but they had to change or leave.
- Quality is important -- no one wants to be called in the middle of the night by an automated system until a problem is fixed which actually happens at Microsoft.
- Tests were taking too long, over 24 hours to run them all.
- Tests failed frequently.
- Tests were written to a very low level.
- MS Testing infrastructure is shared by all teams.
- L1, L2, L3 & L4 tests.
- Tests were written over time and not just overnight for legacy systems.
- Takes 2 weeks to deliver new features to all data centres across the world. MS uses a phased approach which has pros and cons.
- Collect data carefully
  - using MS Application Insights (Project Kusto)
  - Text search queries
  - Ingestion
  - Fast queries over large datasets.
- Monthly Service reports created by a different person in each team every month to action alerts and do uptime reporting.
- Security Mindsets
  - Red vs Blue teams
  - Blind Tests
  - Full disclosure after pen tests are completed. Teams share tactics and lessons learned after the tests are complete. This only happens internally.
  - Continued evolution of the tests
  - "Free iPhone" phising email was sent around MS. Too many people replied.
- After the big changes at Microsoft:
  - Zero tech debt
  - Flattened org chart
  - Features every sprint
  - Team Rooms
  - Customer Engagement
  - Public Shared RoadMap
  - Everyone in Master
  - Test or Leave Ethos
  - General Approach:

**DDD South West 2024 - Domain Driven Design -- Bridging Business & Tech at Lufthansa**

- Ubiquitous language -- BAs and Developers have common language.
- Bounded Context -- Operational changes model
- Aggregates -- Cluster of related objects (entities & values). Treated as a single unit.
- Repos -- Search for persistent stores or databases.
- Domain experts bridge the gaps:
  - Devs work closely with Domain experts.
- Deep understanding of domain and key concepts.
  - Model Business Design in system
  - Domain models created
  - Takes 3 years to mature
- OPSD -- Lufthansa solution:
  Model
  Model
  Domain
- Challenges
  - Can't track events
  - Can't manage transactions
  - If app isn't complex, you don't need DDD.
  - Not favorable for data centric systems but you can use service bus queueing to solve data centric problems.
- Each domain has a microservice
- In Code:
  - Libraries such as "check-in" or "luggage"
  - Link code to doc space
- DDD abstraction is a mindset change
- No abbreviations in DDD and someone comes up with another word for something that already exists, you would say "is it like this?". If yes, you say we use this term for this.

**DDD South West 2024 - Open AI vs Azure AI**

- ChatGPT is OpenAI which was established in 2015 by Elon Musk
- Microsoft owns 49% of OpenAI
- OpenAI examples:
  - Chat GPT
  - Dall-E
  - Whisper
  - TTS
  - Embeddings
- AWS & Anthiopic are working together
- GCP & Gemini using Google Depp Mind
- Playground in Open AI & Azure
- Azure are doing "deploy to webapp" and Azure have added more functionality
- OpenAI has free mode but Azure does not. Azure 100 tokens is 75 words
- Open AI needs a lot of storage for:
  - Vector DB
  - Data for embedding
  - Convo history
  - Prompt Engineering
  - Ethical AI
  - App web/mobile
- Azure:
  - Training data only trains customer model
  - Have SLAs but Open AI does not work to SLAs
- You can jailbreak OpenAI.
- Air Canada blamed chatbot for their chatbot refund advice which landed them in court where they lost.
- DevOps has magic 8 step flow:
  > ![](media/image1.tmp){width="6.268055555555556in" height="3.392361111111111in"}
- Dashboards in "datadog"
  Learning Resources:
- MS Learn
- OpenAI Cookbook
  - "80% - 90% of projects fail" - Gartner statistics
- Azure AI is built on top of the OpenAI offering, with more tools. That's their business model. Same product with other tools built on-top.

**DDD South West 2024 - Burp Suite**

- Pen testers and cyber security testers and platform engineers use this.
- Automated and manual testing and brute force testing
- Acts as a proxy
- Replay and modify request
- Community editions is free
- Burp repeater can update req params and send to requester.
- Intruder feature can:
  - Configure and tailor attacks
  - Add SQL injection attack
- Sitemap Feature:
  - Build good view of all pages to attack.
- Sequencer Feature:
  - Token randomness
  - Find a valid token and make actions on someone's behalf.
- Burp can check:
  - HTTP req and response
  - Rate limiting
  - Logging
  - Observability
  - Alerting
  - CDN config rules
  - Scaling
  - Dependencies
  - Circuit Break
- Run in QA as prod will bring site down with extra traffic.
- Portswagger.net/training
- Act before attackers exploit flaws
- Create security first culture

---
